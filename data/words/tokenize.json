{"id": "tokenize", "metadata": {"operation": "retrieve", "provider": "Oxford University Press", "schema": "RetrieveEntry"}, "results": [{"id": "tokenize", "language": "en-us", "lexicalEntries": [{"entries": [{"grammaticalFeatures": [{"id": "transitive", "text": "Transitive", "type": "Subcategorization"}], "pronunciations": [{"dialects": ["American English"], "phoneticNotation": "respell", "phoneticSpelling": "\u02c8t\u014dk\u0259\u02ccn\u012bz"}, {"audioFile": "https://audio.oxforddictionaries.com/en/mp3/tokenize_us_1.mp3", "dialects": ["American English"], "phoneticNotation": "IPA", "phoneticSpelling": "\u02c8to\u028ak\u0259\u02ccna\u026az"}], "senses": [{"definitions": ["substitute a randomly generated identifier for (a sensitive piece of data) in order to prevent unauthorized access"], "domainClasses": [{"id": "computing", "text": "Computing"}], "domains": [{"id": "computing", "text": "Computing"}], "examples": [{"text": "sensitive data has been tokenized or strongly encrypted"}, {"notes": [{"text": "as adjective \"tokenized\"", "type": "wordFormNote"}], "text": "tokenized payment systems"}], "id": "m_en_gbus1189050.007", "shortDefinitions": ["substitute randomly generated identifier for sensitive piece of data"]}, {"definitions": ["break (text) into individual linguistic units"], "domainClasses": [{"id": "linguistics", "text": "Linguistics"}], "domains": [{"id": "linguistics", "text": "Linguistics"}], "examples": [{"text": "our text gets tokenized into terms"}, {"text": "check if words are tokenized and normalized correctly"}], "id": "m_en_gbus1189050.019", "shortDefinitions": ["break text into individual linguistic units"]}, {"definitions": ["treat (a member of a minority group) as if they have been chosen by way of tokenism"], "domainClasses": [{"id": "politics", "text": "Politics"}], "examples": [{"text": "there was immense diversity and no one was tokenized"}], "id": "m_en_gbus1189050.021", "shortDefinitions": ["treat member of minority group as if chosen by tokenism"]}], "variantForms": [{"regions": [{"id": "british", "text": "British"}], "text": "tokenise"}]}], "language": "en-us", "lexicalCategory": {"id": "verb", "text": "Verb"}, "text": "tokenize"}], "type": "headword", "word": "tokenize"}], "word": "tokenize"}